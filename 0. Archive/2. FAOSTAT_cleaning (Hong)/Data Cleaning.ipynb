{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb37fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import Libraries and Functions\n",
    "\n",
    "import pandas as pd\n",
    "from functions_clean_data import safe_float, find_continents, replace_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4bad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and Preprocess Raw Data\n",
    "\n",
    "# Import the data from the main dataset\n",
    "FAOSTAT = pd.read_csv(\"FAOSTAT_data_2025.csv\")\n",
    "\n",
    "# Convert the values of the 'Value' column, accounting for interval data\n",
    "FAOSTAT['Value'] = FAOSTAT['Value'].apply(\n",
    "    lambda x: safe_float(x) if not isinstance(x, (float, int)) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33152219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Drop Irrelevant or Redundant Columns\n",
    "\n",
    "df = FAOSTAT.drop(['Domain Code', 'Domain', 'Element Code',\n",
    "                   'Element', 'Item Code',\n",
    "                   'Year Code', 'Note', 'Flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d911ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Convert and Enrich Data\n",
    "\n",
    "# Convert values to float to ensure consistency\n",
    "df['Value'] = df['Value'].apply(lambda x: float(x))\n",
    "\n",
    "# Add continent information based on 'Area'\n",
    "df['continents'] = df['Area'].apply(lambda x: find_continents(x))\n",
    "\n",
    "# Replace None values in 'Unit' with a default value like \"index\"\n",
    "df['Unit'] = df['Unit'].apply(replace_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9066df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Group Data for Imputation Preparation\n",
    "\n",
    "# Group the data by year, item, continent, and area for aggregation\n",
    "df_1 = df.groupby(['Year', 'Item', 'continents', 'Area']).agg({\n",
    "    \"Flag Description\": \"first\",\n",
    "    'Unit': 'first',\n",
    "    'Value': 'mean'\n",
    "})\n",
    "df_1.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaf4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. First Stage Imputation (by Year, Item, Continent)\n",
    "\n",
    "# Create list to store imputed values\n",
    "results = []\n",
    "\n",
    "# Loop over each unique item with missing 'Value'\n",
    "for i in df_1.loc[df_1['Value'].isna(), 'Item'].unique():\n",
    "    filtered = df_1[df_1['Item'] == i]\n",
    "    grouped = filtered.groupby(['Year', 'continents']).agg({\n",
    "        'Flag Description': 'first',\n",
    "        'Unit': 'first',\n",
    "        'Value': 'mean',\n",
    "        'Item': 'first'\n",
    "    }).reset_index()\n",
    "    results.append(grouped)\n",
    "\n",
    "# Combine all the grouped results into a single DataFrame\n",
    "means_value_item_one_year = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9408d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Merge First Imputed Values Back\n",
    "\n",
    "# Merge the imputed values back to the main dataframe\n",
    "df_test = df_1.merge(\n",
    "    means_value_item_one_year[['Year', 'Item', 'continents', 'Value']],\n",
    "    on=['Year', 'Item', 'continents'],\n",
    "    how='left',\n",
    "    suffixes=('', '_patch')\n",
    ")\n",
    "\n",
    "# Fill missing values with the patch values\n",
    "df_test['Value'] = df_test['Value'].fillna(df_test['Value_patch'])\n",
    "\n",
    "# Drop the temporary patch column\n",
    "df_test.drop('Value_patch', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a75aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Second Stage Imputation (by Country and Year)\n",
    "\n",
    "# Create list for additional imputation\n",
    "results = []\n",
    "\n",
    "# Loop over remaining missing items\n",
    "for i in df_test.loc[df_test['Value'].isna(), 'Item'].unique():\n",
    "    filtered = df_test[df_test['Item'] == i]\n",
    "    \n",
    "    # Group progressively to get country and year level means\n",
    "    grouped = filtered.groupby(['Item', 'Area', 'Year', 'continents']).agg({\n",
    "        'Flag Description': 'first',\n",
    "        'Unit': 'first',\n",
    "        'Value': 'mean',\n",
    "    }).reset_index()\n",
    "\n",
    "    grouped = grouped.groupby(['Item', 'continents', 'Year']).agg({\n",
    "        'Flag Description': 'first',\n",
    "        'Unit': 'first',\n",
    "        'Value': 'mean',\n",
    "    }).reset_index()\n",
    "\n",
    "    grouped = grouped.groupby(['Item', 'Year']).agg({\n",
    "        'Flag Description': 'first',\n",
    "        'Unit': 'first',\n",
    "        'Value': 'mean',\n",
    "        'continents': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    results.append(grouped)\n",
    "\n",
    "# Combine results into single DataFrame\n",
    "means_value_item_one_year = pd.concat(results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7535ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Merge Secondary Imputed Values into DataFrame\n",
    "\n",
    "df_test = df_test.merge(\n",
    "    means_value_item_one_year[['Year', 'Item', 'Value', 'continents']],\n",
    "    on=['Year', 'Item', 'continents'],\n",
    "    how='left',\n",
    "    suffixes=('', '_patch')\n",
    ")\n",
    "\n",
    "# Fill missing values again\n",
    "df_test['Value'] = df_test['Value'].fillna(df_test['Value_patch'])\n",
    "df_test.drop('Value_patch', axis=1, inplace=True)\n",
    "\n",
    "# Drop rows that are entirely empty (threshold = 1 non-NA required)\n",
    "df_test.dropna(axis=0, inplace=True, thresh=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408b9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Filter Out Irrelevant Items and Continents\n",
    "\n",
    "items_to_drop = [\n",
    "    'Prevalence of exclusive breastfeeding among infants 0-5 months of age (percent)',\n",
    "    'Number of children under 5 years affected by wasting (million)',\n",
    "    'Percentage of children under 5 years affected by wasting (percent)'\n",
    "]\n",
    "continent_to_drop = ['South_America', 'Europe', 'North_America']\n",
    "\n",
    "# Drop the rows based on the item and continent condition\n",
    "df_test = df_test[(~df_test['Item'].isin(items_to_drop)) | (~df_test['continents'].isin(continent_to_drop))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128070df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Export the Cleaned Dataset\n",
    "\n",
    "df_test.to_csv('FAOSTAT.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
